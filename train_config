[DEFAULT]
batch_size = 128
epoch_number = 0
emb_size = 100
kb_emb_size = 100
num_sample = 5
gpu = 3
model_dir = /shared/data/qiz3/text_summ/src/model/
dataset = NYT_example
method = KnowledgeEmbed
id = feb01-hie-nce-lr_0.001
preprocess = True
doc_emb_path = intermediate_data/pretrain_doc.emb
label_emb_path = intermediate_data/pretrain_label.emb
stage = train
summ_method = textrank
topk = 100

